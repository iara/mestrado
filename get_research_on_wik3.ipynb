{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get node, edge and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def read_graph(file):    \n",
    "file = \"grafo.gdf\"\n",
    "\n",
    "with open(file, \"r\") as f:\n",
    "    x = f.readlines()\n",
    "\n",
    "nodedef=[]\n",
    "ini = 0\n",
    "for line in x:\n",
    "    ini+=1\n",
    "    if line.startswith('edgedef'):\n",
    "        break\n",
    "    nodedef.append(line)\n",
    "\n",
    "edgedef = []\n",
    "for line in x[ini-1:]:\n",
    "    edgedef.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_node = nodedef[0].split(\",\")\n",
    "header_list_node =[]\n",
    "\n",
    "column_node_len = len(header_node)\n",
    "\n",
    "for i in range(column_node_len):\n",
    "    label_d = header_node[i].split()[0]\n",
    "    if (i == 0):\n",
    "        label_d = label_d.split(\"nodedef>\")[1]\n",
    "    header_list_node.append(label_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_edge= edgedef[0].split(\",\")\n",
    "column_edge_len = len(header_edge)\n",
    "\n",
    "header_list_edge = []\n",
    "for i in range(column_edge_len):\n",
    "    label_d = header_edge[i].split()[0]\n",
    "    if (i == 0):\n",
    "        label_d = label_d.split(\"edgedef>\")[1]\n",
    "    header_list_edge.append(label_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Construindo objeto Aresta (Nó)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dinamically using metaclasse\n",
    "class Edge(object):\n",
    "    def __init__(self, node1, node2, nivelOrientacao, tipoOrientacao, anoInicio, anoConclusao, node1Nome, node2Nome, directed, node1IsWiki, node2IsWiki):\n",
    "        self._node1 = node1\n",
    "        self._node2 = node2\n",
    "        self._nivelOrientacao = nivelOrientacao\n",
    "        self._tipoOrientacao = tipoOrientacao\n",
    "        self._anoInicio = anoInicio\n",
    "        self._anoConclusao = anoConclusao\n",
    "        self._node1Nome = node1Nome\n",
    "        self._node2Nome = node2Nome\n",
    "        self._directed = directed\n",
    "        self._node1IsWiki = node1IsWiki\n",
    "        self._node2IsWiki = node2IsWiki\n",
    "        \n",
    "        @property\n",
    "        def node1(self):\n",
    "            return self._node1\n",
    "\n",
    "        @node1.setter\n",
    "        def node1(self, node1):\n",
    "            self._node1 = node1\n",
    "        \n",
    "        @property\n",
    "        def node2(self):\n",
    "            return self._node2\n",
    "\n",
    "        @node2.setter\n",
    "        def node2(self, node2):\n",
    "            self._node2 = node2\n",
    "            \n",
    "        @property\n",
    "        def nivelOrientacao(self):\n",
    "            return self._nivelOrientacao\n",
    "\n",
    "        @nivelOrientacao.setter\n",
    "        def nivelOrientacao(self, nivelOrientacao):\n",
    "            self._nivelOrientacao = nivelOrientacao\n",
    "            \n",
    "        @property\n",
    "        def tipoOrientacao(self):\n",
    "            return self._tipoOrientacao\n",
    "\n",
    "        @tipoOrientacao.setter\n",
    "        def tipoOrientacao(self, tipoOrientacao):\n",
    "            self._tipoOrientacao = tipoOrientacao\n",
    "            \n",
    "        @property\n",
    "        def anoInicio(self):\n",
    "            return self._anoInicio\n",
    "\n",
    "        @anoInicio.setter\n",
    "        def anoInicio(self, anoInicio):\n",
    "            self._anoInicio = anoInicio\n",
    "            \n",
    "        @property\n",
    "        def anoConclusao(self):\n",
    "            return self._anoConclusao\n",
    "\n",
    "        @anoConclusao.setter\n",
    "        def anoConclusao(self, anoConclusao):\n",
    "            self._anoConclusao = anoConclusao\n",
    "            \n",
    "        @property\n",
    "        def node1Nome(self):\n",
    "            return self._node1Nome\n",
    "\n",
    "        @node1Nome.setter\n",
    "        def node1Nome(self, node1Nome):\n",
    "            self._node1Nome = node1Nome\n",
    "        \n",
    "        @property\n",
    "        def node2Nome(self):\n",
    "            return self._node2Nome\n",
    "\n",
    "        @node2Nome.setter\n",
    "        def node2Nome(self, node2Nome):\n",
    "            self._node2Nome = node2Nome\n",
    "        \n",
    "        @property\n",
    "        def directed(self):\n",
    "            return self._directed\n",
    "\n",
    "        @directed.setter\n",
    "        def directed(self, directed):\n",
    "            self._directed = directed\n",
    "            \n",
    "        @property\n",
    "        def node1IsWiki(self):\n",
    "            return self._node1IsWiki\n",
    "\n",
    "        @directed.setter\n",
    "        def node1IsWiki(self, node1IsWiki):\n",
    "            self._node1IsWiki = node1IsWiki\n",
    "            \n",
    "        @property\n",
    "        def directed(self):\n",
    "            return self._node2IsWiki\n",
    "\n",
    "        @directed.setter\n",
    "        def node2IsWiki(self, node2IsWiki):\n",
    "            self._node2IsWiki = node2IsWiki\n",
    "        \n",
    "\n",
    "\n",
    "egde_list = []\n",
    "\n",
    "for i in range(1,len(edgedef)):\n",
    "    edge = edgedef[i].split(\",\")\n",
    "    x = Edge(edge[0], edge[1], edge[2], edge[3], edge[4], edge[5], edge[6], edge[7], edge[8], False, False)\n",
    "    egde_list.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo objeto Node (Nó)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, name, label, idLattes, grandeArea, area, instituicao, orgao, pais, estado, cidade, cep, cvdata, foto, eh_semente, eh_ascendente, eh_descendente, eh_Wiki):\n",
    "        self._name = name\n",
    "        self._label = label\n",
    "        self._idLattes = idLattes\n",
    "        self._grandeArea = grandeArea\n",
    "        self._area = area\n",
    "        self._instituicao = instituicao\n",
    "        self._orgao = orgao\n",
    "        self._pais = pais\n",
    "        self._estado = estado\n",
    "        self._cidade = cidade\n",
    "        self._cep = cep\n",
    "        self._cvdata = cvdata\n",
    "        self._foto = foto\n",
    "        self._eh_semente = eh_semente\n",
    "        self._eh_ascendente = eh_ascendente\n",
    "        self._eh_descendente = eh_descendente\n",
    "        self._eh_Wiki = eh_Wiki\n",
    "\n",
    "        @property\n",
    "        def name(self):\n",
    "            return self._name\n",
    "\n",
    "        @name.setter\n",
    "        def name(self, name):\n",
    "            self._name = name\n",
    "        \n",
    "        @property\n",
    "        def label(self):\n",
    "            return self._label\n",
    "\n",
    "        @label.setter\n",
    "        def label(self, label):\n",
    "            self._label = label\n",
    "                    \n",
    "        @property\n",
    "        def idLattes(self):\n",
    "            return self._idLattes\n",
    "\n",
    "        @idLattes.setter\n",
    "        def label(self, idLattes):\n",
    "            self._idLattes = idLattes\n",
    "        \n",
    "        @property\n",
    "        def grandeArea(self):\n",
    "            return self._grandeArea\n",
    "\n",
    "        @grandeArea.setter\n",
    "        def label(self, grandeArea):\n",
    "            self._grandeArea = grandeArea\n",
    "        \n",
    "        @property\n",
    "        def area(self):\n",
    "            return self._area\n",
    "\n",
    "        @area.setter\n",
    "        def label(self, area):\n",
    "            self._area = area\n",
    "            \n",
    "        @property\n",
    "        def instituicao(self):\n",
    "            return self._instituicao\n",
    "\n",
    "        @instituicao.setter\n",
    "        def label(self, instituicao):\n",
    "            self._instituicao = instituicao\n",
    "        \n",
    "        @property\n",
    "        def orgao(self):\n",
    "            return self._orgao\n",
    "\n",
    "        @orgao.setter\n",
    "        def label(self, orgao):\n",
    "            self._orgao = orgao\n",
    "            \n",
    "        @property\n",
    "        def pais(self):\n",
    "            return self._pais\n",
    "\n",
    "        @pais.setter\n",
    "        def label(self, pais):\n",
    "            self._pais = pais\n",
    "            \n",
    "        @property\n",
    "        def estado(self):\n",
    "            return self._estado\n",
    "\n",
    "        @estado.setter\n",
    "        def label(self, estado):\n",
    "            self._estado = estado\n",
    "        \n",
    "        @property\n",
    "        def cidade(self):\n",
    "            return self._cidade\n",
    "\n",
    "        @cidade.setter\n",
    "        def label(self, cidade):\n",
    "            self._cidade = cidade\n",
    "\n",
    "        @property\n",
    "        def cep(self):\n",
    "            return self._cep\n",
    "\n",
    "        @cep.setter\n",
    "        def cep(self, cep):\n",
    "            self._cep = cep\n",
    "        \n",
    "        @property\n",
    "        def cvdata(self):\n",
    "            return self._cvdata\n",
    "\n",
    "        @cvdata.setter\n",
    "        def cvdata(self, cvdata):\n",
    "            self._cvdata = cvdata\n",
    "        \n",
    "        @property\n",
    "        def foto(self):\n",
    "            return self._foto\n",
    "\n",
    "        @foto.setter\n",
    "        def foto(self, foto):\n",
    "            self._foto = foto\n",
    "        \n",
    "        @property\n",
    "        def eh_semente(self):\n",
    "            return self._eh_semente\n",
    "\n",
    "        @eh_semente.setter\n",
    "        def eh_semente(self, eh_semente):\n",
    "            self._eh_semente = eh_semente\n",
    "        \n",
    "        @property\n",
    "        def eh_ascendente(self):\n",
    "            return self._eh_ascendente\n",
    "\n",
    "        @eh_ascendente.setter\n",
    "        def label(self, eh_ascendente):\n",
    "            self._eh_ascendente = eh_ascendente\n",
    "            \n",
    "        @property\n",
    "        def eh_descendente(self):\n",
    "            return self._eh_descendente\n",
    "\n",
    "        @eh_descendente.setter\n",
    "        def eh_descendente(self, eh_descendente):\n",
    "            self._eh_descendente = eh_descendente\n",
    "            \n",
    "        @property\n",
    "        def eh_Wiki(self):\n",
    "            return self._eh_Wiki\n",
    "\n",
    "        @eh_Wiki.setter\n",
    "        def eh_Wiki(self, eh_Wiki):\n",
    "            self._eh_Wiki = eh_Wiki\n",
    "                   \n",
    "node_list = []\n",
    "\n",
    "for i in range(1,len(nodedef)):\n",
    "    node = nodedef[i].split(\",\")\n",
    "    x = Node(node[0], node[1], node[2], node[3], node[4], node[5], node[6], node[7], node[8], node[9], node[10], node[11], node[12], node[13], node[14], node[15], False)\n",
    "    node_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Compute edit distances using Ukkonen, 1985.\n",
    "\n",
    "This module computes edit distances (also called Levenshtein distance)\n",
    "based on the article \"Algorithms for Approximate String Matching\"\n",
    "(Ukkonen, 1985).\n",
    "\n",
    "The 2 functions that should be imported from this module are:\n",
    "\n",
    "+ is_edit_le(s1, s2, le) :: tests if the edit distance is less than or\n",
    "equal to le\n",
    "\n",
    "+ edit_distance(s1, s2) :: the edit distance between the strings s1\n",
    "and s2\n",
    "\n",
    "The most useful function is `is_edit_le' because it is the one that\n",
    "could potentially save CPU cycles if you are only interested on limits\n",
    "of distances.\n",
    "\n",
    "`is_edit_le' needs time O(le * min(m, n)).\n",
    "\n",
    "'''\n",
    "\n",
    "from decimal import Decimal\n",
    "from itertools import count\n",
    "\n",
    "_inf = Decimal('Inf')\n",
    "\n",
    "class _Fkp (dict):\n",
    "    '''Fkp table that extends dict.\n",
    "\n",
    "    Fkp should be used only with 2-tuples and when there is a missing\n",
    "    key, the following is returned:\n",
    "\n",
    "    Fkp[k, p] = |k| - 1, if p = |k| - 1 and k < 0;\n",
    "\n",
    "                -1, if p = |k| - 1;\n",
    "\n",
    "                -inf, otherwise.\n",
    "\n",
    "    '''\n",
    "    def __missing__(self, kp):\n",
    "        k, p = kp\n",
    "        if p == abs(k) - 1:\n",
    "            self[kp] = abs(k) - 1 if k < 0 else -1\n",
    "        else:\n",
    "            self[kp] = -_inf\n",
    "        return self[kp]\n",
    "\n",
    "def _fill_f_kp(k, p, f_kp, s1, s2):\n",
    "    '''Fill f_kp according to algorithm 8 from Ukkonen, 1985.'''\n",
    "    t = max(f_kp[k, p-1] + 1,\n",
    "            f_kp[k-1, p-1],\n",
    "            f_kp[k+1, p-1] + 1)\n",
    "    while t < len(s1) and t + k < len(s2) and s1[t] == s2[t+k]:\n",
    "        t += 1\n",
    "    f_kp[k, p] = t\n",
    "\n",
    "def is_edit_le(s1, s2, le):\n",
    "    '''Return the edit distance if <= le; return le+1 otherwise.\n",
    "\n",
    "    The edit distance between the strings s1 and s2 is the minimum\n",
    "    number of edit operations (insertion, deletion, change) to turn s1\n",
    "    into s2.\n",
    "\n",
    "    This procedure implements algorithm 11 of article \"Algorithms for\n",
    "    Approximate String Matching\" (Ukkonen, 1985).\n",
    "\n",
    "    For example, if you want to test if the edit distance between s1\n",
    "    and s2 are at most 2, call `is_edit_le' with le = 2.  If it\n",
    "    returns anything larger than 2, the edit distance is larger than\n",
    "    2, but you don't know how larger it is.\n",
    "\n",
    "    '''\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "    p = -1\n",
    "    r = p - min(m, n)\n",
    "    f_kp = _Fkp()\n",
    "    while (n-m, p) not in f_kp or f_kp[n-m, p] != m:\n",
    "        p += 1\n",
    "        if p > le:\n",
    "            # The number of edit operations is larger than the limit\n",
    "            # le\n",
    "            return p\n",
    "        r += 1\n",
    "        if r <= 0:\n",
    "            for k in range(-p, p+1):\n",
    "                _fill_f_kp(k, p, f_kp, s1, s2)\n",
    "        else:\n",
    "            for k in range(max(-m, -p), -r+1):\n",
    "                _fill_f_kp(k, p, f_kp, s1, s2)\n",
    "            for k in range (r, min(n, p) + 1):\n",
    "                _fill_f_kp(k, p, f_kp, s1, s2)\n",
    "    return p\n",
    "\n",
    "def edit_distance(s1, s2):\n",
    "    '''Return the edit distance between s1 and s2.\n",
    "\n",
    "    The edit distance between 2 strings is the number of edit\n",
    "    operations (insert, deletion, changes) to turn s1 into s2.\n",
    "\n",
    "    '''\n",
    "    # The edit distance is computed by testing the limit of the\n",
    "    # distance with the sequence <0, 1, 2, 3, ...>.  The testing stops\n",
    "    # as soon as the edit distance matches the limit.\n",
    "    for i in count():\n",
    "        if is_edit_le(s1, s2, i) == i:\n",
    "            return i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo arquivo dbpedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodar no bash se necessário o data_pt\n",
    "#### cat data | awk -F '/' '{print $5}' | sed -e 's/>.*//g' -e 's/_/ /g' | uniq | sort > nomes.txt\n",
    "#### cat nomes.txt  | sed -e \"s/(.*)//g\" -e \"s/,.*//g\" > nomes_limpos.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "from unicodedata import normalize\n",
    "\n",
    "def remover_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "## started 2017-06-27T21:49:19Z\n",
    "arq = open('nomes_limpos.txt', 'r')\n",
    "texto = arq.readlines()\n",
    "arq.close()\n",
    "\n",
    "dicio = {}\n",
    "\n",
    "for i in texto:\n",
    "    nome = i.replace('\\n', '')\n",
    "    nome = remover_acentos(nome)\n",
    "    nome = nome.lower()\n",
    "    dicio[nome] = 'True'\n",
    "\n",
    "\n",
    "for e in egde_list:\n",
    "    if(dicio.get(e._node1Nome.lower(), \"False\") == \"True\"):\n",
    "        e._node1IsWiki = True\n",
    "    if(dicio.get(e._node2Nome.lower(), \"False\") == \"True\"):\n",
    "        e._node2IsWiki = True\n",
    "\n",
    "\n",
    "\n",
    "print(\"fim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025\n",
      "processou pessoas famosas\n",
      "CPU times: user 1.18 s, sys: 12 ms, total: 1.19 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f = open('RESULTADO_exato1.txt', 'w+')\n",
    "f.write(\"Num;Nome_Grafo;Nome_Wiki\" + \"\\n\")\n",
    "f.flush()\n",
    "\n",
    "total_wiki = 0\n",
    "t = 0\n",
    "len(node_list)\n",
    "p=0\n",
    "'''\n",
    "for n in node_list:\n",
    "    p = p + 1\n",
    "    for key in dicio.keys():\n",
    "        word_dicio = remover_acentos(key.lower())\n",
    "        word_node = remover_acentos(n._label.lower())\n",
    "        \n",
    "        if(word_dicio[0] == word_node[0]):\n",
    "        \n",
    "            wd = len(word_dicio)\n",
    "            wn = len(word_node)\n",
    "\n",
    "            if(wd == wn or (wd + 1) == wn or wd == (wn +1)):\n",
    "                if(is_edit_le(word_dicio, word_node, 1) <= 1):\n",
    "                    f.write(str(p) + \";\" + word_node + \";\" + word_dicio + \"\\n\")  \n",
    "                    f.flush()\n",
    "                    n._eh_Wiki = True\n",
    "                    total_wiki=total_wiki+1\n",
    "    t = t + 1\n",
    "    if (t % 1000 == 0):\n",
    "        print(t)\n",
    "\n",
    "f.close()\n",
    "'''\n",
    "\n",
    "total_wiki = 0\n",
    "for n in node_list:\n",
    "    p = p + 1\n",
    "    word_node = remover_acentos(n._label.lower())\n",
    "    \n",
    "    if(dicio.get(word_node, \"False\") == \"True\"):\n",
    "        f.write(str(p) + \";\" + word_node + \";\" + word_node + \"\\n\")  \n",
    "        f.flush()\n",
    "        n._eh_Wiki = True\n",
    "        total_wiki=total_wiki+1\n",
    "\n",
    "        \n",
    "f.close        \n",
    "print(total_wiki)\n",
    "print(\"processou pessoas famosas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refazendo os headers para escrever no gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "header_node = nodedef[0].replace('\\n',', ')\n",
    "header_node = header_node + \"eh_Wiki BOOLEAN\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_edge = edgedef[0].replace('\\n',', ')\n",
    "header_edge = header_edge + \"node1IsWiki VARCHAR, node2IsWiki VARCHAR\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrevendo no novo arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim do novo arquivo\n"
     ]
    }
   ],
   "source": [
    "file = open(\"saida.gdf\",\"w\") \n",
    " \n",
    "file.write(header_node)  \n",
    "\n",
    "for n in node_list:\n",
    "    no = \"\"\n",
    "    no = n._name + \",\" + n._label + \",\" + n._idLattes + \",\" + n._grandeArea + \",\" + n._area + \",\" + n._instituicao + \",\" + n._orgao + n._pais + \",\" + n._estado + \",\" + n._cidade + \",\" + n._cep + \",\" + n._cvdata +  \",\" + n._foto + \",\" + str(n._eh_semente) + \",\" + str(n._eh_ascendente) + \",\" + str(n._eh_descendente).replace('\\n','') + \",\" + str(n._eh_Wiki) + \"\\n\"\n",
    "    file.write(no)\n",
    "\n",
    "file.write(header_edge)\n",
    "\n",
    "for e in egde_list:\n",
    "    no = \"\"\n",
    "    no = e._node1 + \",\" + e._node2 + \",\" + e._nivelOrientacao + \",\" + e._tipoOrientacao + \",\" + e._anoInicio + \",\" + e._anoConclusao + \",\" + e._node1Nome + \",\" + e._node2Nome + \",\" +  str(e._directed).replace('\\n','') + \",\" + str(e._node1IsWiki) + \",\" + str(e._node2IsWiki) + \"\\n\"\n",
    "    file.write(no)\n",
    "    \n",
    "file.close()\n",
    "print(\"Fim do novo arquivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imprime apenas nós de pessoas na Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_pesquisadores = len(node_list)\n",
    "percentual_wiki = total_wiki/total_pesquisadores*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade Total de Pesquisadores (Matematica): 334952\n",
      "Quantidade Total de Pesquisadores na Wiki: 331927\n",
      "Wiki/ Total: 99.09688552389596%\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade Total de Pesquisadores (Matematica): \" + str(len(node_list)))\n",
    "print(\"Quantidade Total de Pesquisadores na Wiki: \" + str(total_wiki))\n",
    "print(\"Wiki/ Total: \" + str(percentual_wiki) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"pessoas_importantes.txt\",\"w\") \n",
    "\n",
    "for n in node_list:\n",
    "    if(n._eh_Wiki== True):\n",
    "        file.write(n._label + \"\\n\")  \n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"Pessoas famosas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## busca em largura (Breath-First Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busca descendentes - jacob palis\n",
      "{'1054911', '10057408'}\n",
      "fim\n"
     ]
    }
   ],
   "source": [
    "lista_adjacencia_descendente={}\n",
    "lista_adjacencia_ascendente={}\n",
    "\n",
    "for i in range(1,len(edgedef)):\n",
    "    edge = edgedef[i].split(\",\")\n",
    "    id_orientador = edge[0]\n",
    "    id_aluno = edge[1]\n",
    "    if(lista_adjacencia_descendente.get(id_orientador, -1) != -1):\n",
    "        lista_adjacencia_descendente[id_orientador].append(id_aluno)\n",
    "    else:\n",
    "        lista_adjacencia_descendente[id_orientador] = [id_aluno]\n",
    "        \n",
    "    if(lista_adjacencia_ascendente.get(id_aluno, -1) != -1):\n",
    "        lista_adjacencia_ascendente[id_aluno].append(id_orientador)\n",
    "    else:\n",
    "        lista_adjacencia_ascendente[id_aluno] = [id_orientador]\n",
    "    '''\n",
    "    atributos = {}\n",
    "    atributos[\"node1\"] = edge[0]\n",
    "    atributos[\"node2\"] = edge[1]\n",
    "    atributos[\"nivelOrientacao\"] = edge[2]\n",
    "    atributos[\"tipoOrientacao\"] = edge[3]\n",
    "    atributos[\"anoInicio\"] = edge[4]\n",
    "    atributos[\"anoConclusao\"] = edge[5]\n",
    "    atributos[\"node1Nome\"] = edge[6]\n",
    "    atributos[\"node2Nome\"] = edge[7]\n",
    "    atributos[\"directed\"] = edge[8]\n",
    "    atributos[\"node1IsWiki\"] = \"False\"\n",
    "    atributos[\"node2IsWiki\"] = \"False\"\n",
    "    '''\n",
    "\n",
    "graph = {}\n",
    "\n",
    "for i in lista_adjacencia_ascendente.keys():\n",
    "    graph[i] = set(lista_adjacencia_ascendente.get(i))\n",
    "    \n",
    "import collections\n",
    "\n",
    "def breadth_first_search(graph, root):\n",
    "    seen, queue = set([root]), collections.deque([root])\n",
    "    while queue:\n",
    "        vertex = queue.popleft()\n",
    "        if(graph.get(vertex, -1) != -1):\n",
    "            for node in graph[vertex]:\n",
    "                if node not in seen:\n",
    "                    seen.add(node)\n",
    "                    queue.append(node)\n",
    "    return(seen)\n",
    "\n",
    "print(\"busca descendentes - jacob palis\")\n",
    "y = breadth_first_search(graph, '1054911')\n",
    "print(y)\n",
    "print(\"fim\")\n",
    "\n",
    "x = dict.fromkeys(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fim do novo arquivo\n"
     ]
    }
   ],
   "source": [
    "file = open(\"jacob_ascendentes.gdf\",\"w\") \n",
    " \n",
    "file.write(header_node)  \n",
    "\n",
    "for n in node_list:\n",
    "    if(x.get(n._name, -1) != -1):\n",
    "        no = \"\"\n",
    "        no = n._name + \",\" + n._label + \",\" + n._idLattes + \",\" + n._grandeArea + \",\" + n._area + \",\" + n._instituicao + \",\" + n._orgao + n._pais + \",\" + n._estado + \",\" + n._cidade + \",\" + n._cep + \",\" + n._cvdata +  \",\" + n._foto + \",\" + str(n._eh_semente) + \",\" + str(n._eh_ascendente) + \",\" + str(n._eh_descendente).replace('\\n','') + \",\" + str(n._eh_Wiki) + \"\\n\"\n",
    "        file.write(no)\n",
    "\n",
    "file.write(header_edge)\n",
    "\n",
    "for e in egde_list:\n",
    "    if(x.get(e._node2, -1) != -1):\n",
    "        no = \"\"\n",
    "        no = e._node1 + \",\" + e._node2 + \",\" + e._nivelOrientacao + \",\" + e._tipoOrientacao + \",\" + e._anoInicio + \",\" + e._anoConclusao + \",\" + e._node1Nome + \",\" + e._node2Nome + \",\" +  str(e._directed).replace('\\n','') + \",\" + str(e._node1IsWiki) + \",\" + str(e._node2IsWiki) + \"\\n\"\n",
    "        file.write(no)\n",
    "    \n",
    "file.close()\n",
    "print(\"Fim do novo arquivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
